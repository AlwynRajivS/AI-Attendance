<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Admin - Face Capture & Recognition</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; background: #f0f2f5; margin: 0; }
    video, canvas { display: block; margin: 10px auto; }
    input, button { padding: 10px; margin: 10px; font-size: 16px; border-radius: 5px; }
    #status { font-weight: bold; color: green; }
    #descLength { font-weight: bold; color: blue; }
  </style>
</head>
<body>
  <h2>Admin - Face Capture & Live Recognition</h2>
  
  <div>
    <input type="text" id="studentName" placeholder="Enter Student Name">
    <button onclick="captureAndSave()">Capture & Save</button>
    <p id="status">Loading models...</p>
    <p id="descLength">Descriptor Length: 0</p>
  </div>

  <video id="video" width="400" height="300" autoplay muted playsinline></video>
  <canvas id="overlay" width="400" height="300"></canvas>

  <script>
    const video = document.getElementById("video");
    const overlay = document.getElementById("overlay");
    const ctx = overlay.getContext("2d");
    const statusEl = document.getElementById("status");
    const descLengthEl = document.getElementById("descLength");

    const WEBAPP_URL = "https://script.google.com/macros/s/AKfycbyHCjSic3B_NjUqA-lomjO5ehqVgRRhUkF1szEtvhCFP-9fuva-4ZH7Bmz9ToSm06BR0Q/exec"; // replace with your Apps Script URL
    let labeledDescriptors = [];
    let faceMatcher;

    // Load models and start video
    async function init() {
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models/"),
          faceapi.nets.faceLandmark68Net.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models/"),
          faceapi.nets.faceRecognitionNet.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models/")
        ]);

        statusEl.innerText = "✅ Models loaded. Starting camera...";
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        video.srcObject = stream;
        video.onplay = () => setInterval(detectAndRecognize, 200);

        // Load saved students
        await loadStudents();
      } catch (err) {
        statusEl.innerText = "❌ Error: " + err.message;
      }
    }

    // Capture & Save student
    async function captureAndSave() {
      const name = document.getElementById("studentName").value.trim();
      if (!name) { alert("Enter student name"); return; }

      const detection = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) { alert("No face detected"); return; }

      const descriptor = Array.from(detection.descriptor);
      descLengthEl.innerText = `Descriptor length: ${descriptor.length}`;

      try {
        const res = await fetch(WEBAPP_URL, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ action: "addStudent", name: name, descriptor: JSON.stringify(descriptor) })
        });
        const result = await res.json();
        if (result.status === "success") {
          statusEl.innerText = `✅ Saved ${name}`;
          await loadStudents(); // refresh descriptors
        } else {
          statusEl.innerText = "❌ Save Error: " + JSON.stringify(result);
        }
      } catch (err) {
        statusEl.innerText = "❌ Save Error: " + err.message;
      }
    }

    // Load students & create LabeledFaceDescriptors
    async function loadStudents() {
      try {
        const res = await fetch(WEBAPP_URL + "?action=getStudents");
        const students = await res.json();

        labeledDescriptors = students.map(s => {
          let descArray = [];
          try { descArray = JSON.parse(s.descriptor); } 
          catch(e) { console.warn("Bad descriptor for", s.name); }
          return new faceapi.LabeledFaceDescriptors(s.name, [new Float32Array(descArray)]);
        });

        faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.5);
        statusEl.innerText = `Loaded ${labeledDescriptors.length} students`;
      } catch (err) {
        statusEl.innerText = "❌ Error loading students: " + err.message;
      }
    }

    // Detection & recognition loop
    async function detectAndRecognize() {
      if (video.readyState !== 4 || !faceMatcher) return;

      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(overlay, displaySize);

      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      ctx.clearRect(0, 0, overlay.width, overlay.height);

      const resized = faceapi.resizeResults(detections, displaySize);

      resized.forEach(d => {
        const bestMatch = faceMatcher.findBestMatch(d.descriptor);
        const box = d.detection.box;
        ctx.strokeStyle = "green";
        ctx.lineWidth = 2;
        ctx.strokeRect(box.x, box.y, box.width, box.height);
        ctx.fillStyle = "green";
        ctx.font = "16px Arial";
        ctx.fillText(bestMatch.toString(), box.x, box.y > 20 ? box.y - 5 : box.y + 15);
      });
    }

    document.addEventListener("DOMContentLoaded", init);
  </script>
</body>
</html>
