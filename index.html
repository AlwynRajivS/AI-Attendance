<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Admin Face Training</title>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; }
    #video { border: 2px solid #444; border-radius: 10px; }
    #descriptorPreview { margin-top: 10px; font-weight: bold; color: green; }
  </style>
</head>
<body>
  <h1>üì∏ Admin ‚Äì Face Capture & Training</h1>

  <video id="video" width="480" height="360" autoplay muted></video>
  <canvas id="overlay" width="480" height="360"></canvas>

  <div>
    <input type="text" id="studentName" placeholder="Enter Student Name">
    <button id="captureBtn">Capture & Save</button>
  </div>

  <!-- ‚úÖ Live preview area -->
  <p id="descriptorPreview">Descriptor Length: 0</p>

  <script>
    const video = document.getElementById("video");
    const overlay = document.getElementById("overlay");
    const ctx = overlay.getContext("2d");
    const descriptorPreview = document.getElementById("descriptorPreview");

    const SHEET_URL = "https://script.google.com/macros/s/AKfycbygGGNe1ytw-NVYVYNN4f75pNDxiH-tqDA499Xsd8GhG64Tdi3HcSTiNV5rwBlT0LaWQg/exec"; // <-- Replace with Apps Script WebApp URL

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights");
      await faceapi.nets.faceLandmark68Net.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights");
      await faceapi.nets.faceRecognitionNet.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights");
      console.log("‚úÖ Models loaded");
    }

    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      video.srcObject = stream;
    }

    document.getElementById("captureBtn").addEventListener("click", async () => {
      const detections = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detections) {
        alert("‚ùå No face detected. Try again.");
        return;
      }

      const descriptor = detections.descriptor;
      const name = document.getElementById("studentName").value.trim();

      if (!name) {
        alert("‚ö†Ô∏è Please enter student name");
        return;
      }

      // ‚úÖ Show live preview of descriptor length
      descriptorPreview.textContent = `Descriptor Length: ${descriptor.length}`;

      // ‚úÖ Send to Google Sheets
      await fetch(SHEET_URL, {
        method: "POST",
        body: JSON.stringify({
          action: "addStudent",
          name: name,
          descriptor: JSON.stringify(Array.from(descriptor)) // store as JSON string
        }),
        headers: { "Content-Type": "application/json" }
      });

      alert(`‚úÖ Saved ${name} to Google Sheet`);
    });

    // Initialize
    loadModels().then(startVideo);
  </script>
</body>
</html>
